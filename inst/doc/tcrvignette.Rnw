%\VignetteIndexEntry{tcR Vignette}
%\VignetteKeyword{TCR}
%\VignetteKeyword{TCR repertoire}
%\VignetteKeyword{TCR analysis}
%\VignetteKeyword{computational immunology}
%\VignetteKeyword{immunoinformatics}
%\VignetteKeyword{immunology}
%\VignettePackage{tcR}
\documentclass{article}

\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=blue,
    filecolor=blue,
    linkcolor=blue,
    urlcolor=blue
}

%\textwidth=6.2in
\textwidth=7in
\textheight=8.5in
% \oddsidemargin=0.2in
% \evensidemargin=0.2in
% \oddsidemargin=0.01in
% \evensidemargin=0.01in
\addtolength{\oddsidemargin}{-.955in}
\addtolength{\evensidemargin}{-.955in}
\headheight=0in
\headsep=0in



\begin{document}
\SweaveOpts{concordance=FALSE}

\newcommand{\Rpackage}[1]{{\textit{#1}}}
\newcommand{\code}[1]{\mbox{\texttt{#1}}}

\title{tcR: a package for T-cell receptor repertoire data analysis}
\author{Vadim Nazarov  \\ \href{mailto:vdm.nazarov@gmail.com}{vdm.nazarov@gmail.com} \\ 
  \and Mikhail Pogorelyy \\ \href{mailto:m.pogorely@gmail.com}{m.pogorely@gmail.com}
}
% Laboratory of Comparative and Functional Genomics, Moscow, Russia
\date{August 2014}
\maketitle

\abstract{Abstract}
High-throughput technologies has open new possibilities to analyse data of repertoires of immunological receptors (i.e., T-cell or B-cell receptors). Here we present a manual to an R package \Rpackage{tcR}. Paper is published in \href{m.pogorely@gmail.com}{Journal of Something}:
\begin{quote}
\texttt{\href{m.pogorely@gmail.com}{Nazarov et al tcR: an R package for T-cell repertoire data analysis.}}
\end{quote}

\tableofcontents


\section{Introduction}
The \Rpackage{tcR} package is designed to help researchers in the immunology field to analyse TCR and BCR repertoires.
In this vignette, we will cover main procedures for TCR repertoire analysis.


\subsection{Package features}
\begin{description}
  \item[-] Shared clones statistics \emph{(number of shared clones, clonotypes, using V-segments or not; Jaccard index for number of shared clones; sequential intersection among the most abundant clones ("top-cross"))}
  \item[-] V- and J-segments usage and it's analysis \emph{(PCA, Shannon Entropy, Jensen-Shannon Divergence)}
  \item[-] Diversity evaluation \emph{(ecological diversity index, Gini index, inverse Simpson index, rarefaction analysis)}
  \item[-] Artificial repertoire generation (beta chain only, for now)
  \item[-] Spectratyping
  \item[-] Various visualisation procedures
\end{description}


\subsection{Data, provided along with the package}
With the package few datasets are provided.

\emph{human.alphabets.rda} - .rda file with character vectors for Variable and Joining segments names for human species.
Few segments are merged together due to inefficiency of our sequencing technology.
User can provide their own alphabets by assigning new character vectors to this alphabets.
Variables stored at this file are: 
<<eval=FALSE>>=
data(human.alphabets)
V_ALPHA_ALPHABET
J_ALPHA_ALPHABET
V_BETA_ALPHABET
J_BETA_ALPHABET
@


\emph{mouse.alphabets.rda} - .rda file with character vector with names for V- and J-segments for mouse species.
Variables stored at this file are:
<<eval=FALSE>>=
data(mouse.alphabets)
V_BETA_ALPHABET
J_BETA_ALPHABET
@


\emph{twa.rda}, \emph{twb.rda} - data frames with downsampled to the 10000 most abundant clonesets and 4 samples data of twins data (alpha and beta chains).
Link: \href{http://labcfg.ibch.ru/tcr.html}{TCR data at Laboratory of Comparative and Functional Genomics}.
Variables:
<<eval=FALSE>>=
data(twa)
head(twa[[1]])
data(twb)
head(twb[[1]])
@


\subsection{Quick start (using examples pipelines with automatic report generation)}
For exploratory analysis of a single repertoire, use the RMarkdown report file:
\begin{quote}
\texttt{<path to the tcR package>/inst/library.report.Rmd}
\end{quote}
Analysis in the file included statistics and visualisation of number of clones, clonotypes, in- and out-of-frames, unique amino acid CDR3 sequences, V- and J-usage, most frequent k-mers, rarefaction analysis. 

For analysis of a group of repertoires ("cross-analysis"), use the RMarkdown report fil:
\begin{quote}
\texttt{<path to the tcR package>/inst/crossanalysis.report.Rmd}
\end{quote}
Analysis in the file included statistics and visualisation of number of shared clones and clonotypes, V-usage for individuals and groups, J-usage for individuals, Jensen-Shannon divergence among V-usages of repertoires and top-cross. 

You will need the \Rpackage{knitr} package installed in order to generate reports from default pipelines. In RStudio you can run a pipeline file as follows:
\begin{quote}
\texttt{Run RStudio -> load the pipeline .Rmd files -> press the knitr button}
\end{quote}


\subsection{MiTCR: a tool for retrieving CDR3 sequences from NGS data}
MiTCR is a tool for retrieving TCR CDR sequences from NGS data (\href{http://www.nature.com/nmeth/journal/v10/n9/full/nmeth.2555.html}{link}). Pipeline for processing files typically looks like follows:
\begin{quote}
\texttt{NGS .fastq files -> run MiTCR -> tab-separated files with clonesets -> tcR parser}
\end{quote}

You can start MiTCR from an R session with \code{startmitcr} function. E.g., to run code above
you need to do following:
<<eval=FALSE>>=
startmitcr('raw/TwA1_B.fastq.gz', 'mitcr/TwA1_B.txt', .file.path = '~/data/',
            pset = 'flex', level = 1, 'debug', .mitcr.path = '~/programs/', .mem = '8g')
@
Run MiTCR on all files from the '~/data/raw/' directory:
<<eval=FALSE>>=
startmitcr(.file.path = '~/data/raw', pset = 'flex', level = 1, 'debug',
            .mitcr.path = '~/programs/', .mem = '8g')
@

For parsing data \Rpackage{tcR} offers \code{parse.file}, \code{parse.file.list} and \code{parse.folder} functions.
<<eval=FALSE>>=
# Parse file in "~/data/twb1.txt".
twb1 <- parse.file("~/data/twb1.txt")
# Parse files "~/data/twb1.txt" and "~/data/immdat2.txt".
twb12 <- parse.file.list(c("~/data/twb1.txt", "~/data/twb2.txt"))
# Parse all files in "~/data/".
twb <- parse.folder("~/data/")
@


\subsection{Structure of a MiTCR data frame (clonesets representation)}
The package basically operates with data frames with specific column names, which called MiTCR data frames. MiTCR data frame is an output file from the MiTCR tool. This files are tab-delimited files with columns stands for CDR3 nucleotide sequence, V-segment and oth.:

<<eval=TRUE,echo=FALSE>>=
library(tcR)
data(twb)
head(twb[[1]])
@


In our analysis only few columns are broadly used. Hence, to do almost all analysis you just need a data frames with following columns:
\begin{description}
  \item[-] \emph{Read.count}
  \item[-] \emph{CDR3.amino.acid.sequence}
  \item[-] \emph{V.segments}
\end{description}
Additionally, for analysis of J-segments usage or nucleotide sequences intersection (see Subsection \ref{subsec:crosses}) you should provide:
\begin{description}
  \item[-] \emph{J.segments}
  \item[-] \emph{CDR3.nucleotide.sequence}
\end{description}
Any data frame with this columns is suitable for processing with the package, hence user can generate their own table files and load them for the further analysis using \code{read.csv}, \code{read.table} and other base R functions.


\section{Repertoire descriptive statistics}
For exploratory analysis, a \Rpackage{tcR} provides functions for computing descriptive statistics.


\subsection{Sequences summary}
To get a general view of subject's repertoire (overall count of sequences, in- and out-of-frames numbers and percentage) use the \code{mitcr.stats} function. It returns a \code{summary} of counts of nucleotide sequences ('clones') and amino acid sequences ('clonotypes'), as well as summary of read counts:
<<eval=TRUE>>=
# Load the package.
library(tcR)
# Load additional packages for making this vignette.
# Load the twins data, provided with the package.
data(twb)
# Load human alphabets of V-genes and J-genes, provided with the package.
data(human.alphabets)
mitcr.stats(twb)
@


\subsection{Percentage and counts of the most abundant clonotypes}
\label{subsec:abundant}
Function \code{clonal.proportion} is used to get the number of most abundant by the count of reads clones. E.g., compute number of clones which fill up (approx.) the 25\% from total repertoire's "Read.count":

<<eval=TRUE>>=
                            # How many clones fill up approximately
clonal.proportion(twb, 25)  # the 25% of the sum of values in 'Read.count'?
@
To get a proportion of the most abundant clones' sum of reads to the overall overlall number of reads in a repertoire, use \code{top.proportion}, i.e. get

\texttt{($\sum$ reads of top clones)$/$($\sum$ reads for all clones).}
E.g., get a proportion of the top-10 clones' reads to the overall number of reads:

<<eval=TRUE,fig=TRUE,height=4,width=7>>=
                          # What accounts a proportion of the top-10 clones' reads
top.proportion(twb, 10)   # to the overall number of reads?
vis.top.proportions(twb)  # Plot this proportions.
@

Function \code{tailbound.proportion} with two arguments \code{.col} and \code{.bound} gets subset of the given data frame with clones having column \code{.col} with value $\leq$ \code{.bound} and computes the ratio of sums of count reads of such subset to the overall data frame. E.g., get proportion of sum of reads of sequences which has "Read.count" <= 100 to the overall number of reads:

<<eval=TRUE,print=TRUE>>=
                                # What is a proportion of sequences which
                                # have 'Read.count' <= 100 to the
tailbound.proportion(twb, 100)  # overall number of reads?
@


\subsection{In- and out-of-frame CDR3 sequences subsetting and statistics}
Functions for performing subsetting and counting cardinality of in-frame and out-of-frame subsets are: \code{count.inframes}, \code{count.outframes}, \code{get.inframes}, \code{get.outframes}. Parameter \code{.head} for this functions is a parameter to the \code{head} function, that applied before subsetting. Functions accept both data frames and list of data frames as parameters. E.g., get data frame with only in-frame sequences and count out-of-frame sequences in the first 5000 rows for this data frame:
<<eval=TRUE>>=
imm.in <- get.inframes(twb) # Return all in-frame sequences from the 'twb'.

                            # Count the number of out-of-frame sequences
count.outframes(twb, 5000)  # from the first 5000 sequences.
head(freq.Vb(imm.in)[,2] / freq.Vb(twb)[,2])       # Compare V-usage between in-frames and all seq.
@
General function with parameter stands for 'all' (all sequences), 'in' (only in-frame sequences) or 'out' (only out-of-frame sequences) is \code{count.frames}:
<<eval=TRUE>>=
imm.in <- get.frames(twb, 'in') # Similar to 'get.inframes(twb)'.

count.frames(twb[[1]], 'all')   # Just return number of rows.

flag <- 'out'
count.frames(twb, flag, 5000)   # Similar to 'count.outframes(twb, 5000)'.
@


\subsection{V-, D-, J-segments statistics}
\label{subsec:usage}
To access V- and J-usage of a repertoire, \Rpackage{tcR} provides functions \code{freq.segments}, \code{freq.segments.2D} and a family of functions \code{freq.[VJ][ab]} for simplier use. Function \code{freq.segments}, depending on parameters, computes frequencies or counts of the given elements (e.g., V-segments) in the given column (e.g., "V.segments") of the input data frame(s). Function \code{freq.segments.2D} computes joint distributions or counts of the two given elements (e.g., V-segments and J-segments). For plotting V-usage and J-usage see section \ref{subsec:segplots}. V and J alphabets for humans are stored in the .rda file "human.alphabets.rda" (they are identical to those form IMGT: \href{http://www.imgt.org/IMGTrepertoire/index.php?section=LocusGenes&repertoire=nomenclatures&species=human&group=TRBV}{link to beta genes (red ones)} and \href{http://www.imgt.org/IMGTrepertoire/index.php?section=LocusGenes&repertoire=nomenclatures&species=human&group=TRAV}{link to alpha genes (red ones)}). All of the mentioned functions are accept data frames as well as list of data frames. Output for those functions are data frames with the first column stands for segment and the other for frequencies.

<<eval=TRUE>>=
# Equivalent to freq.Vb(twb[[1]]) by default.
imm1.vs <- freq.segments(twb[[1]])
head(imm1.vs)
@

<<eval=TRUE>>=
imm.vs.all <- freq.segments(twb)  # Equivalent to freq.Vb(twb) by default.
imm.vs.all[1:10, 1:4]
@

<<eval=TRUE>>=
imm1.vj <- freq.segments.2D(twb[[1]])
imm1.vj[1:5, 1:5]
@

You can also directly visualise segments usage with functions \code{vis.V.usage} and \code{vis.J.usage} with argument \code{.cast.freq} equal to TRUE:
<<eval=TRUE,fig=TRUE,height=4,width=9>>=
# Put ".dodge = F" to get distinct plot for every data frame in the given list.
vis.J.usage(twb, .cast.freq = T, .main = 'twb J-usage dodge', .dodge = T)
@

<<eval=TRUE,fig=TRUE,height=6.5,width=9>>=
vis.J.usage(twb, .cast.freq = T, .main = 'twb J-usage column', .dodge = F, .ncol = 2)
@

<<eval=TRUE,fig=TRUE,height=4,width=7>>=
vis.V.usage(imm1.vs, .cast.freq = F, .main = 'twb[[1]] V-usage', .coord.flip = F)
@


\subsection{Search for a target CDR3 sequences}
For exact or fuzzy search of sequences the package employed a function \code{find.clonotypes}. Input arguments for this function are data frame or list of data frames, targets (character vector or data frame having one column with sequences and additional columns with, e.g., V-segments), value of which column or columns to return, method to be used to compare sequences among each other (either "exact" for exact matching, "hamm" for matching sequences by Hamming distance (two sequences are matched if H <= 1) or "lev" for matching sequences by Levenshtein distance (two sequences are matched if L <= 1)), and name of column name from which sequences for matching are obtained. Sounds very complex, but in practice it's very easy, therefore let's go to examples.
Suppose we want to search for some CDR3 sequences in a number of repertoires:
<<eval=TRUE,echo=FALSE>>=
cmv <- data.frame(CDR3.amino.acid.sequence = c('CASSSANYGYTF', 'CSVGRAQNEQFF', 'CASSLTGNTEAFF', 'CASSALGGAGTGELFF', 'CASSLIGVSSYNEQFF'),
                  V.segments = c('TRBV4-1', 'TRBV4-1', 'TRBV4-1', 'TRBV4-1', 'TRBV4-1'), stringsAsFactors = F)
@

<<eval=TRUE>>=
cmv
@
We will search for them using all methods of matching (exact, hamming or levenshtein) and with and without matching by V-segment. Also, for the first case (exact matching and without V-segment) we return "Total.insertions" column along with the "Read.count" column, and for the second case output will be a "Rank" - rank (generated by \code{set.rank}) of a clone or a clonotype in a data frame.
<<eval=TRUE>>=
twb <- set.rank(twb)
# Case 1.
cmv.imm.ex <- 
  find.clonotypes(.data = twb[1:2], .targets = cmv[,1], .method = 'exact',
                  .col.name = c('Read.count', 'Total.insertions'),
                  .verbose = F)
head(cmv.imm.ex)

# Case 2.
# Search for CDR3 sequences with hamming distance <= 1
# to the one of the cmv$CDR3.amino.acid.sequence with
# matching V-segments. Return ranks of found sequences.
cmv.imm.hamm.v <- 
  find.clonotypes(twb[1:3], cmv, 'hamm', 'Rank', 
                  .target.col = c('CDR3.amino.acid.sequence', 'V.segments'),
                  .verbose = F)
head(cmv.imm.hamm.v)

# Case 3.
# Similar to the previous example, except
# using levenshtein distance and the "Read.count" column.
cmv.imm.lev.v <- 
  find.clonotypes(twb[1:3], cmv, 'lev', 
                  .target.col = c('CDR3.amino.acid.sequence', 'V.segments'),
                  .verbose = F)
head(cmv.imm.lev.v)
@


\section{Cloneset analysis}
Repertoires (both TCRs and BCRs) can be viewed as sets of elements, e.g. sets of CDR3 amino acid sequences or sets of tuples (CDR3 amino acid sequence, V-segment). \Rpackage{tcR} provides functions for evaluating similarity and diversity of such sets.


\subsection{Intersections between sets of CDR3 sequences}
\label{subsec:crosses}
A simplest way to evaluate similarity of two sets is compute the number of elements in their intersection set (i.e., number of shared elements). \Rpackage{tcR} overrides default function \code{intersect}, adding new parameters, thought \code{intersect(x,y)} works as the old function \code{base::intersect} if \code{x} and \code{y} both are not data frames. For data frames \code{base::intersect} isn't working, but \code{tcR::intersect} is: by default the function intersects the "CDR3.nucleotide.sequence" columns of the given data frames, but user can change target columns by using arguments \code{.type} or \code{.col}. As in the \code{find.clonotypes}, user can choose which method apply to the elements: exact match of elements, match by Hamming distance or match by Levenshtein distance.

<<eval=TRUE,fig=TRUE,height=5,width=5>>=
# Equivalent to intersect(twb[[1]]$CDR3.nucleotide.sequence,
#                         twb[[2]]$CDR3.nucleotide.sequence)
# or intersectCount(twb[[1]]$CDR3.nucleotide.sequence,
#                    twb[[2]]$CDR3.nucleotide.sequence)
# "n" stands for a "CDR3.nucleotide.sequence" column, "e" for exact match.
intersect(twb[[1]], twb[[2]], 'n0e')
# "a" stands for "CDR3.amino.acid.sequence" column.
# "v" means that intersect should also use the "V.segments" column.
intersect(twb[[1]], twb[[2]], 'ave')
# Works also on lists, performs all possible pairwise intersections.
intersect(twb, 'ave')
# Plot a heatmap of number of shared clonotypes.
vis.heatmap(intersect(twb, 'ave'), .title = 'twb - (ave)-intersection', .labs = '')
@

See the \code{vis.heatmap} function in the Section "Plots" for the visualisation of the intersection results.

Functions \code{intersectCount}, \code{intersectLogic} and \code{intersectIndices} are more flexible in terms of choosing which columns to match. They all have parameter \code{.col} that specifies names of columns which will used in computing intersection. Function \code{intersectCount} returns number of similar elements; \code{intersectIndices(x, y)} returns 2-column matrix with the first column stands for an index of an element in the given \code{x}, and the second column stands for an index of that element of \code{y} which is similar to a relative element in \code{x}; \code{intersec.logic(x, y)} returns logical vector of \code{length(x)} or \code{nrow(x)}, where TRUE at position \code{i} means that element with index {i} has been found in the \code{y}.

<<eval=TRUE>>=
# Get logic vector of shared elements, where
# elements are tuples of CDR3 nucleotide sequence and corresponding V-segment
imm.1.2 <- intersectLogic(twb[[1]], twb[[2]],
                           .col = c('CDR3.amino.acid.sequence', 'V.segments'))  
# Get elements which are in both twb[[1]] and twb[[2]].
head(twb[[1]][imm.1.2, c('CDR3.amino.acid.sequence', 'V.segments')])
@


\subsection{Top cross}
Number of shared clones among the most abundant clones may differ signigicantly from those with less count. To support research \Rpackage{tcR} offers the \code{top.cross} function. that will apply \code{intersect} to the first 1000 clones, 2000, 3000 and so on up to the first 100000 clones, if supplied \code{.n} == \code{seq(1000, 100000, 1000)}.
<<eval=TRUE,fig=TRUE,height=10,width=14,png=TRUE>>=
twb.top <- top.cross(.data = twb, .n = seq(500, 10000, 500), .verbose = F, .norm = T)
top.cross.plot(twb.top)
@


\subsection{Diversity evaluation}
For assessing the distribution of clones in the given repertoire, \Rpackage{tcR} provides functions for evaluating the diversity (functions \code{diversity} and \code{inverse.simpson}) and the skewness of the clonal distribution (function \code{gini}). Function \code{diversity} computes the ecological diversity index (with parameter \code{.q} for penalties for clones with large count). Function \code{inverse.simpson} computes the Inverse Simpson Index (i.e., inverse probability of choosing two similar clones). Function \code{gini} computes the Gini index of clonal distribution. Function \code{chao1} computes Chao index, its SD and two 95 perc CI.

<<eval=TRUE>>=
# Evaluate the diversity of clones by the ecological diversity index.
sapply(twb, function (x) diversity(x$Read.count))
# Compute the diversity as inverse probability of choosing two similar clones.
sapply(twb, function (x) inverse.simpson(x$Read.count))
# Evaluate the skewness of clonal distribution.
sapply(twb, function (x) gini(x$Read.count))
# Compute diversity of repertoire using Chao index.
t(sapply(twb, function (x) chao1(x$Read.count)))
@

See also the \code{entropy} function for accessing the repertoire diversity, which is described in Subsection \ref{subsec:infomeasures}.


\subsection{More complicated repertoire similarity measures}
\label{subsec:complexcrosses}
\Rpackage{tcR} also provides more complex measures for evaluating the similarity of sets.

$\cdot$ Cosine similarity (function \code{cosine.similarity}) is a measure of similarity between two vectors of an inner product space that measures the cosine of the angle between them.

$\cdot$ Tversky index (function \code{tversky.index}) is an asymmetric similarity measure on sets that compares a variant to a prototype. If using default arguments, it's similar to Dice's coefficient.

$\cdot$ Overlap coefficient (function \code{overlap.coef}) is a similarity measure that measures the overlap between two sets, and is defined as the size of the intersection divided by the smaller of the size of the two sets.

$\cdot$ Morisita's overlap index (function \code{morisitas.index}) is a statistical measure of dispersion of individuals in a population and is used to compare overlap among samples. The formula is based on the assumption that increasing the size of the samples will increase the diversity because it will include different habitats (i.e. different faunas) (Morisita, 1959).

<<eval=TRUE,width=9>>=
cols <- c('CDR3.amino.acid.sequence', 'Read.count')
# Apply the Morisitas overlap index to the each pair of repertoires.
apply.symm(twb, function (x,y) morisitas.index(x[, cols], y[, cols]), .verbose = F)
@

To visualise similarity among repertoires the \code{vis.heatmap} function is appropriate.


\section{Analysis of segments usage}
To evaluate V- and J-segments usage of repertoires, the package implements subroutines for two approaches to analysis: measures from the information theory and PCA (Principal Component Analysis).


\subsection{Information measures}
\label{subsec:infomeasures}
To assess the diversity of segments usage user can use the \code{entropy} function. Kullback-Leibler assymetric measure (function \code{kl.div}) and Jensen-Shannon symmetric measure (functions \code{js.div} for computing JS-divergence between the given distributions, \code{js.div.seg} for computing JS-divergence between segments distributions of two data frame with repertoires or a list with data frames) are provided to estimate distance among segments usage of different repertoires. To visualise distances \Rpackage{tcR} employed the \code{vis.radarlike} function, see Section "Plots" for more detailed information.

<<eval=TRUE,fig=TRUE,width=12,height=8>>=
                              # Transform "0:100" to distribution with Laplace correction 
entropy(0:100, .laplace = 1)  # (i.e., add "1" to every value before transformation).
entropy.seg(twb)  # Compute entropy of V-segment usage for each data frame. Same to
                  # apply(freq.Vb(twb)[,-1], 2, entropy)
# Next expression is equivalent to the expression
# js.div(freq.Vb(twb[[1]])[,2], freq.Vb(twb[[2]])[,2], .norm.entropy = T)
js.div.seg(twb[[1]], twb[[2]], .verbose = F)
# Also works when input arguments are list of data frames.
imm.js <- js.div.seg(twb, .verbose = F) 
vis.radarlike(imm.js, .ncol = 2)
@


\subsection{Principal Component Analysis (PCA)}
Principal component analysis (PCA) is a statistical procedure for transforming a set of observations to a set of special values for analysis. In \Rpackage{tcR} implemented functions \code{pca.segments} for performing PCA on V- or J-usage, and \code{pca.segments.2D} for performing PCA on VJ-usage. For plotting the PCA results see the \code{vis.pca} function.
<<eval=TRUE,fig=TRUE,height=4,width=5,resolution=600>>=
pca.segments(twb)                       # Plot PCA results of V-segment usage.
class(pca.segments(twb, .do.plot = F))  # Return object of class "prcomp"
@


\section{Shared repertoire}
To investigate a shared among a several repertoires clones (or so-called "shared repertoire") the package provided the \code{shared.repertoire} function along with functions for computing the shared repertoire statistics. The \code{shared.representation} function computes the number of shared clones for each repertoire for each degree of sharing (i.e., number of people, in which indicated amount of clones have been found). The function \code{shared.summary} is equivalent to \code{intersection} but on the shared repertoire. Measuring distances among repertoires using the cosine similarity on vector of counts of shared sequences is also possible with the \code{cosine.sharing} function.
<<eval=TRUE>>=
# Compute shared repertoire of amino acid CDR3 sequences and V-segments
# which has been found in two or more people.
imm.shared <- shared.repertoire(.data = twb, .type = 'avc', .min.ppl = 2, .verbose = F)
head(imm.shared)
shared.representation(imm.shared)  # Number of shared sequences.
cosine.sharing(imm.shared)         # Compute cosing similarity on shared sequences.
# It seems like repetoires are clustering in three groups: (1,2), (3,4) and (5,6).
@


\section{Plots}
The package implements rich data visualisation procedures. All of them are described in this chapter, for detailed examples see related Sections.


\subsection{CDR3 length and read count distributions}
Plots of the distribution of CDR3 nucleotide sequences length (function \code{vis.count.len}) and the histogram of "Read.count" number (function \code{vis.number.count}). Input data is either a data frame or a list with data frames.
<<eval=TRUE,fig=TRUE,width=17,height=6>>=
p1 <- vis.count.len(twb[[1]])
p2 <- vis.number.count(twb[[1]])
grid.arrange(p1, p2, ncol = 2)
@


\subsection{Head proportions plot}
For visualisation of proportions of the most abundant clones in a repertoire \Rpackage{tcR} offers the \code{vis.top.proportions} function. As input it's receives either data frame or a list with data frames and an integer vector with number of clones for computing proportions of count for this clones. See Subsection \ref{subsec:abundant} for examples.


\subsection{Visualisation of distances: heatmap and radar-like plot}
Pairwise distances can be represented as qudratic matrices or data frames, where every row and column represented a repertoire, and a value in every cell (i, j) is a distance between repertoires with indices i and j. For plotting quadratic matrices or data frames in \Rpackage{tcR} implemented functions \code{vis.heatmap} and \code{vis.radarlike}. See Subsection \ref{subsec:crosses} and \ref{subsec:complexcrosses} for examples of set intersections procedures, and Subsection \ref{subsec:infomeasures} for distance computing subroutines using methods from Information Theory.


\subsection{Segments usage}
\label{subsec:segplots}
For visualisation of segments usage \Rpackage{tcR} employes subroutines for making classical histograms using functions \code{vis.V.usage} and \code{vis.J.usage}. Functions accept data frames as well as a list of data frames. Data frames could be a repertoire data or data from the \code{freq.segments} function. Using a parameter \code{.dodge}, user can change output between histograms for each data frame in the given list (\code{.dodge} == FALSE) or one histogram for all data, which is very useful for comparing distribution of segments (\code{.dodge} == TRUE). See Subsection \ref{subsec:usage} for examples.



\subsection{PCA}
For quick plotting of results from the \code{prcomp} function (i.e., objects of class \code{prcomp}), \Rpackage{tcR} provides the \code{vis.pca} function. Input argument for it is an object of class \code{prcomp} and a list of groups (vectors of indices) for colour points:
<<eval=TRUE,fig=TRUE,width=5,height=4>>=
imm.pca <- pca.segments(twb, scale. = T, .do.plot = F)
vis.pca(imm.pca, list(AB = c(1,2), CD = c(3,4)))
@


\section{Conclusion}
Feel free to contact us for the package-related or immunoinformatics research-related questions.


\section{Appendix A: Kmers retrieving}
The \Rpackage{tcR} package implements functions for working with k-mers. Function \code{get.kmers} generates k-mers from the given chatacter vector or a data frame with columns for sequences and a count for each sequence.

<<eval=TRUE>>=
head(get.kmers(twb[[1]]$CDR3.amino.acid.sequence, 100, .meat = F, .verbose = F))
head(get.kmers(twb[[1]], .meat = T, .verbose = F))
@


\section{Appendix B: Nucleotide and amino acid sequences manipulation}
The \Rpackage{tcR} package also provides a several number of quick functions for performing classic bioinformatics tasks on strings. For more powerful subroutines see the Bioconductor's \Rpackage{Biostrings} package.


\subsection{Nucleotide sequence manipulation}
Functions for basic nucleotide sequences manipulations: reverse-complement, translation and GC-content computation. All functions are vectorised.
<<eval=TRUE>>=
revcomp(c('AAATTT', 'ACGTTTGGA'))
cbind(bunch.translate(twb[[1]]$CDR3.nucleotide.sequence[1:10]), twb[[1]]$CDR3.amino.acid.sequence[1:10])
gc.content(twb[[1]]$CDR3.nucleotide.sequence[1:10])
@


\subsection{Reverse translation subroutines}
Function \code{codon.variants} returns a list of vectors of nucleotide codons for each letter for each input amino acid sequence. Function \code{translated.nucl.sequences} returns the number of nucleotide sequences, which, when translated, will result in the given amino acid sequence(s). Function \code{reverse.translation} return all nucleotide sequences, which is translated to the given amino acid sequences. Optional argument \code{.nucseq} for each of this function provides restriction for nucleotides, which cannot be changed. All functions are vectorised.
<<eval=TRUE>>=
codon.variants('LQ')
translated.nucl.sequences(c('LQ', 'CASSLQ'))
reverse.translation('LQ')
translated.nucl.sequences('LQ', 'XXXXXG')
codon.variants('LQ', 'XXXXXG')
reverse.translation('LQ', 'XXXXXG')
@


\end{document}